{
  "hash": "2d648232dbaa6bec570d9d9ca7832cf8",
  "result": {
    "markdown": "---\ntitle: \"Problem Set 1\"\nsubtitle: \"Due Wednesday Sep. 7, 10 am\"\nexecute:\n  freeze: auto\n---\n\n\n## Comments\n\n- This covers material in Units 2 and 4 as well as practice with some of the tools we'll use in the course (R Markdown/knitr). \n- It's due at 10 am (Pacific) on September 7, both submitted as a PDF to Gradescope as well as committed to your GitHub repository.\n- Please note my comments in the syllabus about when to ask for help and about working together. **In particular, please give the names of any other students that you worked with on the problem set and indicate in the text or in code comments any specific ideas or code you borrowed from another student or any online reference.**\n\n\n## Formatting requirements\n\n1. Your electronic solution should be in the form of an R markdown file named ps1.Rmd, a Quarto markdown document named ps1.qmd, or a LaTeX+knitr file named ps1.Rtex, with R code chunks included in the file (or read in from a separate code file). Please see the [dynamic documents tutorial](https://berkeley-scf.github.io/tutorial-dynamic-docs) for more information on how to do this.\n\n2. Your PDF submission should be the PDF produced from your Rmd/qmd/Rtex. Your GitHub submission should include the Rmd/qmd/Rtex file, any R code files containing chunks that you read into your Rmd/qmd/Rtex file, and the final PDF, all named according to the [submission guidelines](https://berkeley-stat243.github.io/stat243-fall-2022/howtos/ps-submission.html).\n\n3. Your solution should not just be code - you should have text describing how you approached the problem and what the various steps were. Your code should have comments indicating what each function or block of code does, and for any lines of code or code constructs that may be hard to understand, a comment indicating what that code does. You do not need to (and should not) show exhaustive output, but in general you should show short examples of what your code does to demonstrate its functionality. Please see the [grading rubric](https://berkeley-stat243.github.io/stat243-fall-2022/rubric.html).\n\n## Problems\n\n1. Please read [these lecture notes](https://36-750.github.io/tools/computer-architecture) about how computers work, used in a class on statistical computing at CMU. In particular, make sure you know the difference between disk and memory. You don't need to turn anything in for this problem.\n\n2. This problem explores file sizes in light of understanding storage in ASCII plain text versus binary formats and the fact that numbers are (generally) stored as 8 bytes per number in binary format.\n\n    a. Explain the sizes of the two files created below. In discussing the CSV text file, how many characters do you expect to be in the file (i.e., you should be able to estimate this very accurately from first principles *without* using `wc` or any explicit program that counts characters). Hint: what do we know about numbers drawn from a standard normal distribution?\n\n\n       ::: {.cell hash='ps1_cache/html/ps2a_3a0ea4e44c9734d01edb0b87ace2a41a'}\n       \n       ```{.r .cell-code}\n       n <-  1e7\n       a <- matrix(rnorm(n), ncol = 100)\n       a <- round(a, 10)\n       \n       fn_csv <- tempfile(fileext = 'csv')\n       write.table(a, file = fn_csv, quote=FALSE, row.names=FALSE,\n                      col.names = FALSE, sep=',')\n       fn_rda <- tempfile(fileext = 'Rda')\n       save(a, file = fn_rda, compress = FALSE)\n       \n       file.size(fn_csv)\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n       [1] 133889265\n       ```\n       :::\n       \n       ```{.r .cell-code}\n       file.size(fn_rda)\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n       [1] 80000096\n       ```\n       :::\n       :::\n\n\n    b. Now consider saving out the numbers one row per number. Given we no longer have to save all the commas, why is the file size unchanged?\n\n\n       ::: {.cell hash='ps1_cache/html/ps2b_9fd5559aff8e6ec1e439c8c63cd77951'}\n       \n       ```{.r .cell-code}\n       b <- a\n       dim(b) <- c(1e7, 1)  ## change to one column by adjusting attribute\n       fn_csv_onecol <- tempfile(fileext = 'csv')\n       write.table(b, file = fn_csv_onecol, quote=FALSE,\n            row.names=FALSE, col.names = FALSE, sep=',')\n       file.size(fn_csv_onecol)\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n       [1] 133889265\n       ```\n       :::\n       :::\n\n\n    c. Consider the following ways of reading the data into R (though similar results would be obtained in other languages). Explain the difference in speed between the three situations. Side note: in this case `readr::read_csv()` is rather faster than `read.csv()`.\n\n\n       ::: {.cell hash='ps1_cache/html/ps2c_7d471b26fd29b611ebde1c2d9986e08c'}\n       \n       ```{.r .cell-code}\n       system.time(a1 <- read.csv(fn_csv, header = FALSE))\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n          user  system elapsed \n        27.635   0.336  27.979 \n       ```\n       :::\n       \n       ```{.r .cell-code}\n       system.time(a2 <- read.csv(fn_csv, header = FALSE,\n                           colClasses = 'numeric'))\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n          user  system elapsed \n         2.473   0.056   2.530 \n       ```\n       :::\n       \n       ```{.r .cell-code}\n       system.time(a3 <- scan(fn_csv, sep = ','))\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n          user  system elapsed \n         2.469   0.032   2.503 \n       ```\n       :::\n       :::\n\n\n    d. Explain why `tmp.Rda` is so much bigger than `tmp2.Rda` given they both contain the same number of numeric values. \n\n\n       ::: {.cell hash='ps1_cache/html/ps2d_175adadfba75cac4e99a967cd07007d2'}\n       \n       ```{.r .cell-code}\n       fn1_rda <- tempfile(fileext = 'Rda')\n       save(a, file = fn1_rda)\n       file.size(fn1_rda)\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n       [1] 76779127\n       ```\n       :::\n       \n       ```{.r .cell-code}\n       b <- rep(rnorm(1), 1e7)\n       fn2_rda <- tempfile(fileext = 'Rda')\n       save(b, file = fn2_rda)\n       file.size(fn2_rda)\n       ```\n       \n       ::: {.cell-output .cell-output-stdout}\n       ```\n       [1] 116506\n       ```\n       :::\n       :::\n\n\n3. Please read Unit 4 on good programming/project practices and incorporate what youâ€™ve learned from that reading into your solution for Problem 4. As your response to this question, briefly (a few sentences) note what you did in your code for Problem 4 that reflects the material in Sections 1.2 and 1.3 of Unit 4. Please also note anything in Unit 4 that you disagree with, if you have a different stylistic perspective.\n\n4. Go to [Google Scholar](https://scholar.google.com) and enter the\n    name (including first name to help with disambiguation) for a\n    researcher whose work interests you. (If you want to do the one that\n    will match the problem set solutions, you can use \"Jennifer Chayes\",\n    who is Berkeley's dean for data science.) If you've entered the\n    name of a researcher that Google Scholar recognizes as having a\n    Google Scholar profile, you should see that the first item returned\n    is a \"User profile\". Next, if you click on the hyperlink for the\n    researcher under \"User profiles for \\<researcher name\\>\", you'll see\n    that brings you to a page that provides the citations for all of the\n    researcher's papers.  **IMPORTANT: if you repeatedly query the Google Scholar site too\n    quickly, Google will start returning \"503\" errors because it detects\n    automated usage (see problem 5 below). So, if you are going to run\n    code from a script such that multiple queries would get done in\n    quick succession, please put something like `Sys.sleep(2)` in\n    between the calls that do the HTTP requests. Also when developing\n    your code, once you have the code in part (a) working to download\n    the HTML, use the downloaded HTML to develop the remainder of your\n    code and don't keep re-downloading the HTML as you work on the\n    remainder of the code.**\n\n    a. Now, based on the information returned by your work above,\n        including the various URLs that your searching and clicking\n        generated, write R code that will programmatically return the\n        citation page for your researcher. Specifically, write a\n        function whose input is the character string of the name of the\n        researcher and whose output is the HTML (as an object of class\n        `xml_document`) corresponding to the researcher's citation page\n        as well as the researcher's Google Scholar ID.\n        \n        Hint: you will need to use some string processing functions to\n        extract the Scholar ID (and possibly for other things) from the\n        output of the various *rvest* functions. I recommend functions\n        from the `stringr` package (we'll see these in Unit 5 and you\n        can find information in Section 2.1.2 of the string processing\n        tutorial), in particular: `str_detect()`, `str_extract()`,\n        `str_split()`, and `str_replace()`. You should NOT need to use\n        regular expressions (which we'll cover in Unit 5), but you can\n        if you want/know how to. Finally if you get an error message\n        like this\n        \"`Syntax error in regexp pattern. (U_REGEX_RULE_SYNTAX)`\", it\n        means the string processing function is interpreting the\n        characters you are looking for as a regular expression. Simply\n        wrap the string you are looking for in the `fixed()` function,\n        e.g., `fixed('sdf?=sd34')` so the characters are simply\n        interpreted as regular characters (i.e., interpreted literally).\n\n    b.  Create a second function to process the resulting HTML to create\n        an R data frame that contains the article title, authors,\n        journal information, year of publication, and number of\n        citations as five columns of information. Try your function on a\n        second researcher to provide more confidence that your function\n        is working properly.\n\n    c.  Include checks in your code so that it fails gracefully if the\n        user provides invalid input or Google Scholar doesn't return a\n        result. You don't have to use the `assertthat` package as we\n        won't cover that until Section on Sep. 9, but you can if you\n        want.\n\n    d.  (Extra credit) Fix your function so that you get all of the\n        results for a researcher and not just the first 20. \n\n    Hint: as you are trying to understand the structure of the HTML, one\n    option is to use `write_xml()` on the result of `read_html()` and\n    then view the file that is produced in a text editor.\n\n    Note: For simplicity you can either assume only one User Profile\n    will be returned by your initial search or that you can just use the\n    first of the profiles.\n\n\n5. Look at the `robots.txt` for Google Scholar (scholar.google.com) and the references in Unit 2 on the ethics of webscraping. Does it seem like it's ok to scrape data from Google Scholar?\n\n6. (Extra Credit) The `reticulate` package and R Markdown allow you to have Python and R chunks in a document that interact with each other. Demonstrate the ability to use this functionality, in particular sending data from R to Python and back to R, with some processing done in Python (it doesn't have to be complicated processing). \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}