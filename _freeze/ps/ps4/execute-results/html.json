{
  "hash": "0c48b2058d0720b2ed0c2f7037f14d77",
  "result": {
    "markdown": "---\ntitle: \"Problem Set 4\"\nsubtitle: \"Due Wednesday Oct. 12, 10 am\"\nformat:\n  pdf:\n    documentclass: article\n    margin-left: 30mm\n    margin-right: 30mm\n    toc: false\n  html:\n    theme: cosmo\n    css: ../styles.css\n    toc: false\n    code-copy: true\n    code-block-background: true\nexecute:\n  freeze: auto\n---\n\n\n\n\n## Comments\n\n- This covers Unit 5.\n- It's due at 10 am (Pacific) on October 12, both submitted as a PDF to Gradescope as well as committed to your GitHub repository.\n- Please see PS1 and the grading rubric for formatting and attribution requirements.\n- I just noticed that the `pryr` package has been superseded by functionality in other packages, particularly by `lobstr` in terms of our uses of `pryr`. So I suggest you use `lobstr::obj_addr`, `lobstr::obj_size`, and `lobstr::mem_used` in place of `pryr::address`, `pryr::object_size`, and `pryr::mem_used` respectively. That said, you'll likely need `.Internal(inspect())` for your solutions for the more granular information it provides.\n\n## Problems\n\n1.  This question explores memory use and copying with character\n    vectors.\n\n    a.  Consider the following character vector with three strings. Modify one of the\n        strings. Can R make the change in place? (Be careful, there are\n        two aspects to this, so it's a bit more complicated than simply\n        replacing an element in a numeric vector.) Also note that you\n        may need to copy-paste output from R or RStudio as compiling the\n        PDF may change the answer.\n\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        vec <- c(\"hello there\", \"better luck next time\", \"that's not clear\")\n        ```\n        :::\n\n\n\n    b.  Now consider this vector: `vec <- c(rep('hello friend', 1e6))`.\n        Given each character should take 1 byte, this would seemingly\n        use 12 million bytes. How much memory is being used? Explain\n        what is happening and account for all major uses of memory.\n\n    c.  Compare the size of the string 'hello' with that of a single\n        string of length 1 million characters (i.e., one where `nchar()`\n        returns 1 million). Does each character take up 1 byte? What\n        does this comparison suggest about short strings?\n\n    Warning: Recall that rendering your Rmd can result in the memory allocation/address information being incorrect, so you are likely to need to paste in some results manually. \n\n\n2.  If I want to compute the trace of a matrix, $A=XY$, where both $X$\n    and $Y$ are $n\\times n$ and where the trace is\n    $\\sum_{i=1}^{n}A_{ii}$, a naive implementation is\n    `sum(diag(X%*%Y))`.\n\n    1.  What is the computational complexity of that naive\n        implementation: $O(n),$ $O(n^{2})$ or $O(n^{3})$?\n        You can just count up the number of multiplications and ignore the additions.\n\n    2.  Why is that naive implementation inefficient?\n\n    3.  How could you (much) more efficiently compute the trace in R\n        using vectorized operations on the matrices. Please provide R\n        code and do not use `apply()`? What is the computational complexity of\n        your solution?\n\n    4.  Create a plot to demonstrate the quadratic vs. cubic scaling using a few values of $n$.\n\n3.   Suppose we have a matrix in which each row is a vector\nof probabilities that add to one, and we want to generate a categorical\nsample based on each row. E.g., the first row might be (0.9, 0.05, 0.05)\nand the second row might be (0.1, 0.85, .0.5). When we generate the\nfirst sample, it is very likely to be a 1 and the second sample is very\nlikely to be a 2. We could do this using a for loop over the rows of the\nmatrix, and `sample()`, but that is a lot slower than some\nother ways we might do it because it is a loop executing in R over many\nelements.\n\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     n <- 100000\n     p <- 5  ## number of categories\n     \n     ## way to generate a random matrix of row-normalized probabilities:\n     tmp <- exp(matrix(rnorm(n*p), nrow = n, ncol = p))\n     probs <- tmp / rowSums(tmp)\n     \n     smp <- rep(0, n)\n     \n     ## loop by row and use sample()\n     set.seed(1)\n     system.time(\n       for(i in seq_len(n))\n             smp[i] <- sample(p, 1, prob = probs[i, ])\n     )\n     ```\n     :::\n\n\n\n      a. Consider transposing the matrix and looping over columns. Why might I hypothesize that this could be faster? Is it faster?\n\n      b. How can we do it much faster? (Hint: This might involve looping or not, but not in the ways described above. Think about how one can use random uniform numbers to generate from a categorical distribution.)\n\n4.   Suppose I run the code `plot(xvec, yvec)`. It's the case that `range()` is called when making the axis limits. Suppose I create a function called `range()` in my R session and then make my plot, as follows.\n\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     n <- 10\n     xvec <- rnorm(n)\n     yvec <- rnorm(n)\n     \n     range <- function(...) print(\"better luck next time\")\n     range(rnorm(3))\n     ## [1] \"better luck next time\"\n     \n     plot(xvec, yvec)\n     ```\n     :::\n\n\n\n     Explain **in detail** why can I still make a plot. As part of your answer, say what functions are on the call stack at the point that `range()` is called and how the \"right\" `range` is found.\n\n5. (Extra credit) Consider `plot(xvec, rnorm(5))`. Explain how it is that the x-axis and y-axis labels can be assigned to be \"xvec\" and \"rnorm(5)\". The material in the optional Section 10 of Unit 5 will be useful.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}